# Safe-Heaven
## Detecting Hate Speech with Sentiment Analysis and ML
Safe Haven is an AI-powered platform designed to combat online harms by detecting hate speech effectively and efficiently. By leveraging sentiment analysis and machine learning (ML), this project aspires to create a safer digital environment by identifying and moderating harmful content. The project incorporates two models:

A Python-based model, built from scratch using Google Colab, designed for high accuracy in detecting online harms.

A JavaScript inbuilt library with adjustable sentiment analysis and moderation levels, allowing customizable sensitivity.

The Python model has shown superior performance in identifying hate speech, demonstrating the potential of advanced ML methods in safeguarding online communities.

## Table of Contents
1. [About the Project](#about-the-project)
2. [Features](#features)
3. [Technologies Used](#technologies-used)
4. [Setup and Installation](#setup-and-installation)
5. [Usage](#usage)
## About the Project
Safe Haven was developed as part of the GDG Solutions Hackathon 2025, addressing the challenge "Scaling Trust: AI-Powered Detection of Online Harms." This innovative project aims to mitigate online harms by identifying and moderating hate speech using cutting-edge sentiment analysis and machine learning techniques.

The project consists of two models:

Python Model: Built from scratch, it employs advanced ML algorithms for reliable detection of hate speech.

JavaScript Model: Utilizes a sentiment analysis library with adjustable moderation levels, providing flexibility to adapt to varying requirements.

## Features
*Dual-Model System: Combines the robustness of the Python model with the flexibility of the JavaScript library.

*Effective Hate Speech Detection: The Python model outperforms in identifying harmful content.

*Adjustable Moderation Levels: The JavaScript library allows users to customize sensitivity according to their needs.

*Real-time Processing: Both models efficiently analyze input to provide immediate results.

*Scalability: Designed to handle high-volume online data streams.

## Technologies Used
**Python**: Core programming language for the first model (developed in Google Colab).

**JavaScript**: Used in the second model for sentiment analysis.

**Node.js**: Backend runtime environment for the JavaScript model.

**React.js**: Frontend library to build an intuitive user interface.

**MongoDB and Mongoose**: Database and ORM (Object Relational Mapper) for seamless data management.

**Express.js**: Framework to streamline server-side development.

**Machine Learning Libraries**: Supporting the Python model.

## Setup and Installation
## Python Model
1. Open Google Colab and upload the Python script.

2. Install the necessary libraries by running:
   pip install -r requirements.txt
3. Run the script to train and deploy the model.

## JavaScript Model
1. Clone the repository from GitHub:
   git clone https://github.com/Su-creator-spec/safe-heaven/tree/main
2. Navigate to the project directory:
   cd safe-heaven
3. Install the required dependencies:
   npm install


## Usage
## Python Model
*Execute the script in Google Colab to analyze data and detect hate speech. The results will be generated in real-time.
## JavaScript Model
Run the application by starting the server:
npm start
*Adjust the moderation levels for tailored sensitivity to harmful content.


